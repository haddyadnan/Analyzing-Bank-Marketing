{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_mxoA7GwG0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fTRSkEowG07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "813fbb75-45ab-4c31-90e0-23715906c777"
      },
      "source": [
        "data = pd.read_csv(\"bank-additional-full.csv\", sep = ';') ; data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>307</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age        job  marital  ... euribor3m nr.employed   y\n",
              "0   56  housemaid  married  ...     4.857      5191.0  no\n",
              "1   57   services  married  ...     4.857      5191.0  no\n",
              "2   37   services  married  ...     4.857      5191.0  no\n",
              "3   40     admin.  married  ...     4.857      5191.0  no\n",
              "4   56   services  married  ...     4.857      5191.0  no\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe1d3gUCwG1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddf5b244-fa83-49ad-c30a-bf85e3ed9193"
      },
      "source": [
        "#%%writefile data.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, QuantileTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def preprocess(df):#, linear = False):\n",
        "\n",
        "    '''\n",
        "    parameters\n",
        "    ----------\n",
        "    df : A pandas dataframe\n",
        "          should contain the data\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    X_train, X_test, y_train, y_test\n",
        "      A pandas dataframe of the train and test set that has been transformed with PCA and minority class over sampling\n",
        "    \n",
        "    '''\n",
        "    #perform feature engineering and data preprocessing\n",
        "    d = {'yes':1, 'no':0}\n",
        "    y = df.y.replace(d)\n",
        "    df['new_pdays'] = df['pdays'].apply(lambda x: 1 if x < 16 else 0 if x > 30 else 2)\n",
        "    df['new_pdays'] = df['previous'] * df['new_pdays']\n",
        "    df['new_emp_rate'] = df['emp.var.rate'].apply(lambda x: 0 if x > 0 else 1)\n",
        "    df['empxemp'] = (df['nr.employed'] / df['euribor3m'])# + df[emp.var.rate]\n",
        "    \n",
        "    #Turn categorical columns to dummies\n",
        "    X = pd.get_dummies(df.drop(['y','cons.conf.idx','previous'], axis = 1))\n",
        "    \n",
        "    #Split data into train and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .1, random_state = 12)\n",
        "    print('The shape of the train set is {}, the shape of the test set is {}'.format(X_train.shape, X_test.shape))\n",
        "    \n",
        "   # if linear:\n",
        "#         print('Generating  polynomials')\n",
        "\n",
        "#         poly = PolynomialFeatures(2)\n",
        "#         X_train = poly.fit_transform(X_train)\n",
        "#         X_test = poly.transform(X_test)\n",
        "        \n",
        "    #Scale the data\n",
        "    S = StandardScaler()\n",
        "    \n",
        "    #Apply the transformation on the train and test set \n",
        "    X_train = S.fit_transform(X_train)\n",
        "    X_test = S.transform(X_test)\n",
        "    \n",
        "    #Apply PCA on the train and test set\n",
        "    pca = PCA(10)\n",
        "    x_train_pca = pca.fit_transform(X_train)\n",
        "    x_test_pca = pca.transform(X_test)\n",
        "    \n",
        "    #Oversample the minority class\n",
        "    sm = SMOTE(k_neighbors=10, random_state= 10)\n",
        "    \n",
        "    X_m, y_m = sm.fit_sample(x_train_pca, y_train)\n",
        "    \n",
        "    return X_m, x_test_pca, y_m, y_test"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing data.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoJ_0gk5wG1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6a026e49-0d54-480c-956d-ba7508a4b27d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = preprocess(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the train set is (37069, 64), the shape of the test set is (4119, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoPfzbnxHnYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtwM0pYWHyTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dc2090f-ff63-4d4d-e481-a05b91629b7b"
      },
      "source": [
        "%%writefile model.py\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold, KFold\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import hp, tpe\n",
        "from hyperopt.fmin import fmin\n",
        "import numpy as np\n",
        "\n",
        "class model():\n",
        "\n",
        "  def __init__(self, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    '''\n",
        "    This class implements Logistic Regression, Multi layer Perceptron and extreme gradient boosting algorithm\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_train : Dataframe, numpy 2D array\n",
        "               The train set to be used for training\n",
        "    X_test :  Dataframe, Numpy 2D array\n",
        "              The hold out set, to be used for validating the model perfomancce\n",
        "    y_train : pandas series, numpy 1D array\n",
        "               Labels for the train set\n",
        "    y_test : pandas series, numpy 1D array\n",
        "              Label for the test set\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    logit : To fit the data using logistic regression\n",
        "    MLP : To fit the data using Multi layered perceptron\n",
        "    XGB : To fit the data using extreme gradient boosting\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    Score\n",
        "      A 5 fold cross validation score\n",
        "    \n",
        "    Example\n",
        "    ------\n",
        "    M = model(X_train, X_test, y_train, y_test)\n",
        "    M.logit() #To fit logistic regression\n",
        "    '''\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.X_test = X_test\n",
        "    self.y_train = y_train\n",
        "    self.y_test = y_test\n",
        "\n",
        "\n",
        "  def evaluate(self, X_train, X_test, y_train, y_test, model):\n",
        "\n",
        "    '''\n",
        "    Evaluate the performance of the model\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    X_train : Dataframe, numpy 2D array\n",
        "               The train set to be used for training\n",
        "    X_test :  Dataframe, Numpy 2D array\n",
        "              The hold out set, to be used for validating the model perfomancce\n",
        "    y_train : pandas series, numpy 1D array\n",
        "               Labels for the train set\n",
        "    y_test : pandas series, numpy 1D array\n",
        "              Label for the test set\n",
        "    model : instance\n",
        "            A fitted instance of the model\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    f1_score on the train set and test set\n",
        "    classification report of the test set\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    evaluate(X_train, X_test, y_train, y_test)\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    #Obtain train and test f1 score\n",
        "    train_score = f1_score(y_train, model.predict(X_train))\n",
        "    test_score =  f1_score(y_test, model.predict(X_test))\n",
        "\n",
        "    #Print scores and classification report\n",
        "    print (f'train score is {train_score}, test_score is {test_score}')\n",
        "    print('----------------------------------------------------------')\n",
        "    print(classification_report(y_test, model.predict(X_test)))\n",
        "\n",
        "  \n",
        "  def objective_xgb(self, params):\n",
        "\n",
        "    '''\n",
        "    Define optimization objective for XGBOOST\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    params : dict\n",
        "            Model parameters to be optimized\n",
        "\n",
        "    Return:\n",
        "    ------\n",
        "    Cross validationn score\n",
        "\n",
        "    '''\n",
        "\n",
        "    #set parameters to tune\n",
        "    params = {\n",
        "        'max_depth': int(params['max_depth']),\n",
        "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
        "        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n",
        "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
        "    }\n",
        "    \n",
        "    #fit model with parameters\n",
        "    xgb = XGBClassifier(random_state=23, **params, n_estimators=300)\n",
        "    #get cv score\n",
        "    skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    \n",
        "    #Obtain cross validation score\n",
        "    score_skf = cross_val_score(xgb, self.X_train, self.y_train, scoring='f1', cv = skf).mean()\n",
        "    score_kf = cross_val_score(xgb, self.X_train, self.y_train, scoring='f1', cv = kf).mean()\n",
        "\n",
        "    #print scores\n",
        "    print(\"stratifiedKFold score {}, Kfold_score {}, params {}\".format(score_skf,score_kf, params))\n",
        "    return score_skf\n",
        "\n",
        "\n",
        "  def logit(self):\n",
        "    '''\n",
        "    Fit Logistic regression model\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    Cross validation score\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    #Call the model\n",
        "    print('fitting Logistic regression...')\n",
        "    lr = LogisticRegression(random_state= 10, max_iter = 10000, )\n",
        "    #fit model\n",
        "    lr.fit(self.X_train, self.y_train)\n",
        "    #Obtain and print AUC Score for test and train\n",
        "    self.evaluate(self.X_train, self.X_test, self.y_train, self.y_test, lr)\n",
        "    \n",
        "    '''Hyper Parameter Search and Cross Validation for logistic Regression'''\n",
        "    \n",
        "    print('Searching for best hyperparameter... ')\n",
        "    #Set params\n",
        "    params = {'C': np.linspace(0.0001,0.001,20)}\n",
        "    \n",
        "    #Init and fit grid search\n",
        "    lr_grid = RandomizedSearchCV(LogisticRegression(random_state = 10, max_iter = 10000), params,\n",
        "                                 scoring='f1', cv =10,  n_iter = 20)\n",
        "    lr_grid.fit(self.X_train, self.y_train)\n",
        "    print('--------------------------------------\\nDONE')\n",
        "    print(f'Best Score {lr_grid.best_score_} Best Param {lr_grid.best_params_}')\n",
        "    self.evaluate(self.X_train, self.X_test, self.y_train, self.y_test,lr_grid.best_estimator_ )\n",
        "    \n",
        "    print('Running Cross Val \\nReturning 5fold CV Scores')\n",
        "    print('--------------------------------------')\n",
        "    \n",
        "    #stratified kfold\n",
        "    skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    \n",
        "    skf_score = cross_val_score(lr_grid.best_estimator_, self.X_train, self.y_train, scoring = 'f1', cv = skf).mean()\n",
        "    kf_score = cross_val_score(lr_grid.best_estimator_, self.X_train, self.y_train, scoring = 'f1', cv = kf).mean()\n",
        "\n",
        "    \n",
        "    print('--------------------------------------\\nDONE')\n",
        "    print('StratifiedKfold Score: {}, KFold Score: {}'.format(skf_score, kf_score))\n",
        "  \n",
        "\n",
        "  def MLP(self):\n",
        "    '''\n",
        "    Fit MLP model\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    Cross validation score\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    #Call the model\n",
        "    print('fitting MLP...')\n",
        "    mlp = MLPClassifier(random_state= 10, early_stopping= True, learning_rate= 'adaptive')\n",
        "    #fit model\n",
        "    mlp.fit(self.X_train, self.y_train)\n",
        "    #Obtain and print AUC Score for test and train\n",
        "    self.evaluate(self.X_train, self.X_test, self.y_train, self.y_test, mlp)\n",
        "    \n",
        "    '''Hyper Parameter Search and Cross Validation for logistic Regression'''\n",
        "    \n",
        "    print('Searching for best hyperparameter... ')\n",
        "    #Set params\n",
        "    params = {'hidden_layer_sizes': np.arange(100,600,100), \n",
        "             'learning_rate_init': np.linspace(0.001,0.003,5)}\n",
        "    \n",
        "    #Init and fit grid search\n",
        "    mlp_grid = RandomizedSearchCV(MLPClassifier(random_state= 10, early_stopping= True, learning_rate= 'adaptive'), params,\n",
        "                                 scoring='f1', cv =10,  n_iter = 20, n_jobs = 12)\n",
        "    mlp_grid.fit(self.X_train, self.y_train)\n",
        "    print('--------------------------------------\\nDONE')\n",
        "    print(f'Best Score {mlp_grid.best_score_} Best Param {mlp_grid.best_params_}')\n",
        "    self.evaluate(self._train, self.X_test, self.y_train, self.y_test,mlp_grid.best_estimator_ )\n",
        "    \n",
        "    print('Running Cross Val \\nReturning 5fold CV Scores')\n",
        "    print('--------------------------------------')\n",
        "    \n",
        "    #stratified kfold\n",
        "    skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    \n",
        "    skf_score = cross_val_score(mlp_grid.best_estimator_, self.X_train, self.y_train, scoring = 'f1', cv = skf).mean()\n",
        "    kf_score = cross_val_score(mlp_grid.best_estimator_, self.X_train, self.y_train, scoring = 'f1', cv = kf).mean()\n",
        "\n",
        "    \n",
        "    print('--------------------------------------\\nDONE')\n",
        "    print('StratifiedKfold Score: {}, KFold Score: {}'.format(skf_score, kf_score))\n",
        "\n",
        "\n",
        "  def XGB(self):\n",
        "    '''\n",
        "    Fit XGBOOST\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    Cross validation score\n",
        "    '''\n",
        "    \n",
        "    #Call the model\n",
        "    print('fitting xgboost...')\n",
        "    xgb = XGBClassifier(random_state= 10, n_estimators = 1000,  use_best_model = True, verbosity=0)\n",
        "    #fit model\n",
        "    xgb.fit(self.X_train, self.y_train, eval_set = [(self.X_test, self.y_test)], eval_metric = 'auc', early_stopping_rounds = 100, verbose = 0 )\n",
        "    #Obtain and print AUC Score for test and train\n",
        "    self.evaluate(self.X_train, self.X_test, self.y_train, self.y_test, xgb)\n",
        "    \n",
        "    '''Hyper Parameter Search and Cross Validation for logistic Regression'''\n",
        "    \n",
        "    print('Searching for best hyperparameter... ')\n",
        "    #Set params\n",
        "    \n",
        "    space_xgb = {\n",
        "        'max_depth': hp.quniform('max_depth', 2, 5, 1),\n",
        "        'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
        "        'gamma': hp.uniform('gamma', 0.0, 0.5),\n",
        "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.5)\n",
        "    }\n",
        "\n",
        "    print('Running Cross Val \\nReturning 5fold CV Scores')\n",
        "    print('--------------------------------------')\n",
        "    \n",
        "    best_xgb = fmin(fn=self.objective_xgb,\n",
        "            space=space_xgb,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=10)\n",
        "    \n",
        "    best_xgb['max_depth'] = int(best_xgb['max_depth'])\n",
        "    \n",
        "    print('--------------------------------------\\nDONE')\n",
        "    print(f'Best Params {best_xgb}')\n",
        "    \n",
        "    skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    xgb = XGBClassifier(n_estimators=10, random_state = 42, **best_xgb)\n",
        "\n",
        "    skf_score = cross_val_score(xgb, self.X_train, self.y_train, scoring = 'f1', cv = skf).mean()\n",
        "    kf_score = cross_val_score(xgb, self.X_train, self.y_train, scoring = 'f1', cv = kf).mean()\n",
        "    \n",
        "    \n",
        "    print('--------------------------------------\\nDONE')\n",
        "    print('StratifiedKfold Score: {}, KFold Score: {}'.format(skf_score, kf_score))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hQoIDiZ41Ia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5036826-5a8f-454b-e088-980f1dbb8698"
      },
      "source": [
        "m = model(*preprocess(data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the train set is (37069, 64), the shape of the test set is (4119, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0uKzNezUZDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "00a52121-55fc-4bb5-953d-b9482ce8d0b9"
      },
      "source": [
        "m.logit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting Logistic regression...\n",
            "train score is 0.7204054431046774, test_score is 0.36596736596736595\n",
            "----------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.74      0.83      3666\n",
            "           1       0.25      0.69      0.37       453\n",
            "\n",
            "    accuracy                           0.74      4119\n",
            "   macro avg       0.60      0.72      0.60      4119\n",
            "weighted avg       0.87      0.74      0.78      4119\n",
            "\n",
            "Searching for best hyperparameter... \n",
            "--------------------------------------\n",
            "DONE\n",
            "Best Score 0.7207422962145781 Best Param {'C': 0.0001}\n",
            "train score is 0.7205527831094051, test_score is 0.3648725212464589\n",
            "----------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.73      0.83      3666\n",
            "           1       0.25      0.71      0.36       453\n",
            "\n",
            "    accuracy                           0.73      4119\n",
            "   macro avg       0.60      0.72      0.60      4119\n",
            "weighted avg       0.88      0.73      0.78      4119\n",
            "\n",
            "Running Cross Val \n",
            "Returning 5fold CV Scores\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "DONE\n",
            "StratifiedKfold Score: 0.7210462079847259, KFold Score: 0.7209996690135231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCk95t2oUclT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "485d6776-ea12-487d-f2c3-eb9567a36917"
      },
      "source": [
        "m.MLP()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting MLP...\n",
            "train score is 0.8332098074508795, test_score is 0.44731182795698926\n",
            "----------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.83      0.89      3666\n",
            "           1       0.33      0.69      0.45       453\n",
            "\n",
            "    accuracy                           0.81      4119\n",
            "   macro avg       0.64      0.76      0.67      4119\n",
            "weighted avg       0.89      0.81      0.84      4119\n",
            "\n",
            "Searching for best hyperparameter... \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SizS1oOBUoqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5177ef6c-613a-4cae-c1bc-b91da78246b5"
      },
      "source": [
        "m.XGB()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting xgboost...\n",
            "[0]\tvalidation_0-auc:0.774015\n",
            "Will train until validation_0-auc hasn't improved in 100 rounds.\n",
            "[1]\tvalidation_0-auc:0.7773\n",
            "[2]\tvalidation_0-auc:0.779476\n",
            "[3]\tvalidation_0-auc:0.782204\n",
            "[4]\tvalidation_0-auc:0.785559\n",
            "[5]\tvalidation_0-auc:0.785522\n",
            "[6]\tvalidation_0-auc:0.786294\n",
            "[7]\tvalidation_0-auc:0.788089\n",
            "[8]\tvalidation_0-auc:0.787723\n",
            "[9]\tvalidation_0-auc:0.788459\n",
            "[10]\tvalidation_0-auc:0.787645\n",
            "[11]\tvalidation_0-auc:0.789069\n",
            "[12]\tvalidation_0-auc:0.789923\n",
            "[13]\tvalidation_0-auc:0.789804\n",
            "[14]\tvalidation_0-auc:0.789022\n",
            "[15]\tvalidation_0-auc:0.788505\n",
            "[16]\tvalidation_0-auc:0.786867\n",
            "[17]\tvalidation_0-auc:0.786994\n",
            "[18]\tvalidation_0-auc:0.787021\n",
            "[19]\tvalidation_0-auc:0.787275\n",
            "[20]\tvalidation_0-auc:0.78716\n",
            "[21]\tvalidation_0-auc:0.786897\n",
            "[22]\tvalidation_0-auc:0.786754\n",
            "[23]\tvalidation_0-auc:0.786899\n",
            "[24]\tvalidation_0-auc:0.786756\n",
            "[25]\tvalidation_0-auc:0.786995\n",
            "[26]\tvalidation_0-auc:0.786016\n",
            "[27]\tvalidation_0-auc:0.786167\n",
            "[28]\tvalidation_0-auc:0.78578\n",
            "[29]\tvalidation_0-auc:0.785639\n",
            "[30]\tvalidation_0-auc:0.786788\n",
            "[31]\tvalidation_0-auc:0.787396\n",
            "[32]\tvalidation_0-auc:0.788211\n",
            "[33]\tvalidation_0-auc:0.788313\n",
            "[34]\tvalidation_0-auc:0.788044\n",
            "[35]\tvalidation_0-auc:0.789741\n",
            "[36]\tvalidation_0-auc:0.789694\n",
            "[37]\tvalidation_0-auc:0.789397\n",
            "[38]\tvalidation_0-auc:0.789604\n",
            "[39]\tvalidation_0-auc:0.789097\n",
            "[40]\tvalidation_0-auc:0.789306\n",
            "[41]\tvalidation_0-auc:0.789287\n",
            "[42]\tvalidation_0-auc:0.789723\n",
            "[43]\tvalidation_0-auc:0.789963\n",
            "[44]\tvalidation_0-auc:0.790547\n",
            "[45]\tvalidation_0-auc:0.79039\n",
            "[46]\tvalidation_0-auc:0.791449\n",
            "[47]\tvalidation_0-auc:0.791765\n",
            "[48]\tvalidation_0-auc:0.791694\n",
            "[49]\tvalidation_0-auc:0.792211\n",
            "[50]\tvalidation_0-auc:0.792106\n",
            "[51]\tvalidation_0-auc:0.792097\n",
            "[52]\tvalidation_0-auc:0.792578\n",
            "[53]\tvalidation_0-auc:0.792325\n",
            "[54]\tvalidation_0-auc:0.792538\n",
            "[55]\tvalidation_0-auc:0.792653\n",
            "[56]\tvalidation_0-auc:0.792986\n",
            "[57]\tvalidation_0-auc:0.793212\n",
            "[58]\tvalidation_0-auc:0.79328\n",
            "[59]\tvalidation_0-auc:0.79393\n",
            "[60]\tvalidation_0-auc:0.794346\n",
            "[61]\tvalidation_0-auc:0.794409\n",
            "[62]\tvalidation_0-auc:0.794349\n",
            "[63]\tvalidation_0-auc:0.794408\n",
            "[64]\tvalidation_0-auc:0.794597\n",
            "[65]\tvalidation_0-auc:0.794972\n",
            "[66]\tvalidation_0-auc:0.79474\n",
            "[67]\tvalidation_0-auc:0.795085\n",
            "[68]\tvalidation_0-auc:0.795468\n",
            "[69]\tvalidation_0-auc:0.795286\n",
            "[70]\tvalidation_0-auc:0.795244\n",
            "[71]\tvalidation_0-auc:0.795681\n",
            "[72]\tvalidation_0-auc:0.795784\n",
            "[73]\tvalidation_0-auc:0.795917\n",
            "[74]\tvalidation_0-auc:0.796113\n",
            "[75]\tvalidation_0-auc:0.795928\n",
            "[76]\tvalidation_0-auc:0.796104\n",
            "[77]\tvalidation_0-auc:0.796412\n",
            "[78]\tvalidation_0-auc:0.796748\n",
            "[79]\tvalidation_0-auc:0.796661\n",
            "[80]\tvalidation_0-auc:0.796629\n",
            "[81]\tvalidation_0-auc:0.796526\n",
            "[82]\tvalidation_0-auc:0.797143\n",
            "[83]\tvalidation_0-auc:0.797252\n",
            "[84]\tvalidation_0-auc:0.797325\n",
            "[85]\tvalidation_0-auc:0.797401\n",
            "[86]\tvalidation_0-auc:0.797517\n",
            "[87]\tvalidation_0-auc:0.797635\n",
            "[88]\tvalidation_0-auc:0.797941\n",
            "[89]\tvalidation_0-auc:0.798324\n",
            "[90]\tvalidation_0-auc:0.798531\n",
            "[91]\tvalidation_0-auc:0.798558\n",
            "[92]\tvalidation_0-auc:0.798509\n",
            "[93]\tvalidation_0-auc:0.798168\n",
            "[94]\tvalidation_0-auc:0.798081\n",
            "[95]\tvalidation_0-auc:0.798029\n",
            "[96]\tvalidation_0-auc:0.798638\n",
            "[97]\tvalidation_0-auc:0.7986\n",
            "[98]\tvalidation_0-auc:0.798782\n",
            "[99]\tvalidation_0-auc:0.79914\n",
            "[100]\tvalidation_0-auc:0.799475\n",
            "[101]\tvalidation_0-auc:0.799466\n",
            "[102]\tvalidation_0-auc:0.799481\n",
            "[103]\tvalidation_0-auc:0.799697\n",
            "[104]\tvalidation_0-auc:0.799755\n",
            "[105]\tvalidation_0-auc:0.799591\n",
            "[106]\tvalidation_0-auc:0.799789\n",
            "[107]\tvalidation_0-auc:0.799431\n",
            "[108]\tvalidation_0-auc:0.79977\n",
            "[109]\tvalidation_0-auc:0.79998\n",
            "[110]\tvalidation_0-auc:0.800265\n",
            "[111]\tvalidation_0-auc:0.80051\n",
            "[112]\tvalidation_0-auc:0.800789\n",
            "[113]\tvalidation_0-auc:0.80082\n",
            "[114]\tvalidation_0-auc:0.800906\n",
            "[115]\tvalidation_0-auc:0.800825\n",
            "[116]\tvalidation_0-auc:0.800768\n",
            "[117]\tvalidation_0-auc:0.801036\n",
            "[118]\tvalidation_0-auc:0.801107\n",
            "[119]\tvalidation_0-auc:0.801347\n",
            "[120]\tvalidation_0-auc:0.801755\n",
            "[121]\tvalidation_0-auc:0.801713\n",
            "[122]\tvalidation_0-auc:0.801777\n",
            "[123]\tvalidation_0-auc:0.801961\n",
            "[124]\tvalidation_0-auc:0.80208\n",
            "[125]\tvalidation_0-auc:0.802064\n",
            "[126]\tvalidation_0-auc:0.802122\n",
            "[127]\tvalidation_0-auc:0.801915\n",
            "[128]\tvalidation_0-auc:0.80194\n",
            "[129]\tvalidation_0-auc:0.801738\n",
            "[130]\tvalidation_0-auc:0.801705\n",
            "[131]\tvalidation_0-auc:0.801886\n",
            "[132]\tvalidation_0-auc:0.801892\n",
            "[133]\tvalidation_0-auc:0.801668\n",
            "[134]\tvalidation_0-auc:0.801647\n",
            "[135]\tvalidation_0-auc:0.801872\n",
            "[136]\tvalidation_0-auc:0.802165\n",
            "[137]\tvalidation_0-auc:0.802025\n",
            "[138]\tvalidation_0-auc:0.802373\n",
            "[139]\tvalidation_0-auc:0.802579\n",
            "[140]\tvalidation_0-auc:0.802596\n",
            "[141]\tvalidation_0-auc:0.80276\n",
            "[142]\tvalidation_0-auc:0.802651\n",
            "[143]\tvalidation_0-auc:0.802902\n",
            "[144]\tvalidation_0-auc:0.803218\n",
            "[145]\tvalidation_0-auc:0.803616\n",
            "[146]\tvalidation_0-auc:0.803596\n",
            "[147]\tvalidation_0-auc:0.803358\n",
            "[148]\tvalidation_0-auc:0.80312\n",
            "[149]\tvalidation_0-auc:0.803031\n",
            "[150]\tvalidation_0-auc:0.803186\n",
            "[151]\tvalidation_0-auc:0.803327\n",
            "[152]\tvalidation_0-auc:0.803575\n",
            "[153]\tvalidation_0-auc:0.803787\n",
            "[154]\tvalidation_0-auc:0.803683\n",
            "[155]\tvalidation_0-auc:0.80377\n",
            "[156]\tvalidation_0-auc:0.803771\n",
            "[157]\tvalidation_0-auc:0.804085\n",
            "[158]\tvalidation_0-auc:0.804392\n",
            "[159]\tvalidation_0-auc:0.804483\n",
            "[160]\tvalidation_0-auc:0.804547\n",
            "[161]\tvalidation_0-auc:0.804881\n",
            "[162]\tvalidation_0-auc:0.804969\n",
            "[163]\tvalidation_0-auc:0.804806\n",
            "[164]\tvalidation_0-auc:0.804874\n",
            "[165]\tvalidation_0-auc:0.804984\n",
            "[166]\tvalidation_0-auc:0.805032\n",
            "[167]\tvalidation_0-auc:0.805179\n",
            "[168]\tvalidation_0-auc:0.805394\n",
            "[169]\tvalidation_0-auc:0.805213\n",
            "[170]\tvalidation_0-auc:0.805131\n",
            "[171]\tvalidation_0-auc:0.805057\n",
            "[172]\tvalidation_0-auc:0.80511\n",
            "[173]\tvalidation_0-auc:0.805301\n",
            "[174]\tvalidation_0-auc:0.805468\n",
            "[175]\tvalidation_0-auc:0.805263\n",
            "[176]\tvalidation_0-auc:0.805024\n",
            "[177]\tvalidation_0-auc:0.805121\n",
            "[178]\tvalidation_0-auc:0.805336\n",
            "[179]\tvalidation_0-auc:0.805471\n",
            "[180]\tvalidation_0-auc:0.805934\n",
            "[181]\tvalidation_0-auc:0.806153\n",
            "[182]\tvalidation_0-auc:0.806272\n",
            "[183]\tvalidation_0-auc:0.80671\n",
            "[184]\tvalidation_0-auc:0.806401\n",
            "[185]\tvalidation_0-auc:0.806316\n",
            "[186]\tvalidation_0-auc:0.806507\n",
            "[187]\tvalidation_0-auc:0.806516\n",
            "[188]\tvalidation_0-auc:0.806568\n",
            "[189]\tvalidation_0-auc:0.806917\n",
            "[190]\tvalidation_0-auc:0.807221\n",
            "[191]\tvalidation_0-auc:0.80723\n",
            "[192]\tvalidation_0-auc:0.807535\n",
            "[193]\tvalidation_0-auc:0.807479\n",
            "[194]\tvalidation_0-auc:0.807615\n",
            "[195]\tvalidation_0-auc:0.807791\n",
            "[196]\tvalidation_0-auc:0.807627\n",
            "[197]\tvalidation_0-auc:0.80751\n",
            "[198]\tvalidation_0-auc:0.807569\n",
            "[199]\tvalidation_0-auc:0.807724\n",
            "[200]\tvalidation_0-auc:0.807295\n",
            "[201]\tvalidation_0-auc:0.807243\n",
            "[202]\tvalidation_0-auc:0.807283\n",
            "[203]\tvalidation_0-auc:0.807202\n",
            "[204]\tvalidation_0-auc:0.807492\n",
            "[205]\tvalidation_0-auc:0.807479\n",
            "[206]\tvalidation_0-auc:0.807661\n",
            "[207]\tvalidation_0-auc:0.807653\n",
            "[208]\tvalidation_0-auc:0.807767\n",
            "[209]\tvalidation_0-auc:0.807874\n",
            "[210]\tvalidation_0-auc:0.807909\n",
            "[211]\tvalidation_0-auc:0.808083\n",
            "[212]\tvalidation_0-auc:0.807907\n",
            "[213]\tvalidation_0-auc:0.807869\n",
            "[214]\tvalidation_0-auc:0.808268\n",
            "[215]\tvalidation_0-auc:0.808496\n",
            "[216]\tvalidation_0-auc:0.808418\n",
            "[217]\tvalidation_0-auc:0.808295\n",
            "[218]\tvalidation_0-auc:0.808434\n",
            "[219]\tvalidation_0-auc:0.808345\n",
            "[220]\tvalidation_0-auc:0.808293\n",
            "[221]\tvalidation_0-auc:0.80842\n",
            "[222]\tvalidation_0-auc:0.808516\n",
            "[223]\tvalidation_0-auc:0.808515\n",
            "[224]\tvalidation_0-auc:0.808859\n",
            "[225]\tvalidation_0-auc:0.808905\n",
            "[226]\tvalidation_0-auc:0.808879\n",
            "[227]\tvalidation_0-auc:0.809054\n",
            "[228]\tvalidation_0-auc:0.809006\n",
            "[229]\tvalidation_0-auc:0.809057\n",
            "[230]\tvalidation_0-auc:0.809213\n",
            "[231]\tvalidation_0-auc:0.809312\n",
            "[232]\tvalidation_0-auc:0.809263\n",
            "[233]\tvalidation_0-auc:0.809539\n",
            "[234]\tvalidation_0-auc:0.809509\n",
            "[235]\tvalidation_0-auc:0.809527\n",
            "[236]\tvalidation_0-auc:0.809561\n",
            "[237]\tvalidation_0-auc:0.809564\n",
            "[238]\tvalidation_0-auc:0.809572\n",
            "[239]\tvalidation_0-auc:0.809731\n",
            "[240]\tvalidation_0-auc:0.809838\n",
            "[241]\tvalidation_0-auc:0.81012\n",
            "[242]\tvalidation_0-auc:0.810321\n",
            "[243]\tvalidation_0-auc:0.810349\n",
            "[244]\tvalidation_0-auc:0.810486\n",
            "[245]\tvalidation_0-auc:0.810597\n",
            "[246]\tvalidation_0-auc:0.810512\n",
            "[247]\tvalidation_0-auc:0.810622\n",
            "[248]\tvalidation_0-auc:0.810679\n",
            "[249]\tvalidation_0-auc:0.810742\n",
            "[250]\tvalidation_0-auc:0.81069\n",
            "[251]\tvalidation_0-auc:0.810805\n",
            "[252]\tvalidation_0-auc:0.810804\n",
            "[253]\tvalidation_0-auc:0.811129\n",
            "[254]\tvalidation_0-auc:0.81145\n",
            "[255]\tvalidation_0-auc:0.811309\n",
            "[256]\tvalidation_0-auc:0.811449\n",
            "[257]\tvalidation_0-auc:0.811582\n",
            "[258]\tvalidation_0-auc:0.811633\n",
            "[259]\tvalidation_0-auc:0.811626\n",
            "[260]\tvalidation_0-auc:0.811309\n",
            "[261]\tvalidation_0-auc:0.811742\n",
            "[262]\tvalidation_0-auc:0.811892\n",
            "[263]\tvalidation_0-auc:0.812036\n",
            "[264]\tvalidation_0-auc:0.812089\n",
            "[265]\tvalidation_0-auc:0.812106\n",
            "[266]\tvalidation_0-auc:0.81233\n",
            "[267]\tvalidation_0-auc:0.812321\n",
            "[268]\tvalidation_0-auc:0.812153\n",
            "[269]\tvalidation_0-auc:0.812263\n",
            "[270]\tvalidation_0-auc:0.811832\n",
            "[271]\tvalidation_0-auc:0.811906\n",
            "[272]\tvalidation_0-auc:0.811942\n",
            "[273]\tvalidation_0-auc:0.812021\n",
            "[274]\tvalidation_0-auc:0.811985\n",
            "[275]\tvalidation_0-auc:0.812191\n",
            "[276]\tvalidation_0-auc:0.812037\n",
            "[277]\tvalidation_0-auc:0.812094\n",
            "[278]\tvalidation_0-auc:0.811809\n",
            "[279]\tvalidation_0-auc:0.812011\n",
            "[280]\tvalidation_0-auc:0.812101\n",
            "[281]\tvalidation_0-auc:0.812248\n",
            "[282]\tvalidation_0-auc:0.812543\n",
            "[283]\tvalidation_0-auc:0.812631\n",
            "[284]\tvalidation_0-auc:0.812745\n",
            "[285]\tvalidation_0-auc:0.812373\n",
            "[286]\tvalidation_0-auc:0.812525\n",
            "[287]\tvalidation_0-auc:0.812711\n",
            "[288]\tvalidation_0-auc:0.812554\n",
            "[289]\tvalidation_0-auc:0.812483\n",
            "[290]\tvalidation_0-auc:0.812572\n",
            "[291]\tvalidation_0-auc:0.812725\n",
            "[292]\tvalidation_0-auc:0.812787\n",
            "[293]\tvalidation_0-auc:0.812832\n",
            "[294]\tvalidation_0-auc:0.81287\n",
            "[295]\tvalidation_0-auc:0.812966\n",
            "[296]\tvalidation_0-auc:0.813102\n",
            "[297]\tvalidation_0-auc:0.813241\n",
            "[298]\tvalidation_0-auc:0.813164\n",
            "[299]\tvalidation_0-auc:0.81327\n",
            "[300]\tvalidation_0-auc:0.8134\n",
            "[301]\tvalidation_0-auc:0.813034\n",
            "[302]\tvalidation_0-auc:0.812943\n",
            "[303]\tvalidation_0-auc:0.81301\n",
            "[304]\tvalidation_0-auc:0.812891\n",
            "[305]\tvalidation_0-auc:0.812602\n",
            "[306]\tvalidation_0-auc:0.812793\n",
            "[307]\tvalidation_0-auc:0.812713\n",
            "[308]\tvalidation_0-auc:0.812651\n",
            "[309]\tvalidation_0-auc:0.812675\n",
            "[310]\tvalidation_0-auc:0.812869\n",
            "[311]\tvalidation_0-auc:0.812901\n",
            "[312]\tvalidation_0-auc:0.812842\n",
            "[313]\tvalidation_0-auc:0.8129\n",
            "[314]\tvalidation_0-auc:0.812809\n",
            "[315]\tvalidation_0-auc:0.81284\n",
            "[316]\tvalidation_0-auc:0.812849\n",
            "[317]\tvalidation_0-auc:0.812957\n",
            "[318]\tvalidation_0-auc:0.813001\n",
            "[319]\tvalidation_0-auc:0.813044\n",
            "[320]\tvalidation_0-auc:0.813061\n",
            "[321]\tvalidation_0-auc:0.813085\n",
            "[322]\tvalidation_0-auc:0.813075\n",
            "[323]\tvalidation_0-auc:0.813103\n",
            "[324]\tvalidation_0-auc:0.813121\n",
            "[325]\tvalidation_0-auc:0.813241\n",
            "[326]\tvalidation_0-auc:0.81347\n",
            "[327]\tvalidation_0-auc:0.813664\n",
            "[328]\tvalidation_0-auc:0.813678\n",
            "[329]\tvalidation_0-auc:0.813746\n",
            "[330]\tvalidation_0-auc:0.81394\n",
            "[331]\tvalidation_0-auc:0.814244\n",
            "[332]\tvalidation_0-auc:0.81414\n",
            "[333]\tvalidation_0-auc:0.814555\n",
            "[334]\tvalidation_0-auc:0.814853\n",
            "[335]\tvalidation_0-auc:0.814531\n",
            "[336]\tvalidation_0-auc:0.814625\n",
            "[337]\tvalidation_0-auc:0.814562\n",
            "[338]\tvalidation_0-auc:0.814812\n",
            "[339]\tvalidation_0-auc:0.814877\n",
            "[340]\tvalidation_0-auc:0.815276\n",
            "[341]\tvalidation_0-auc:0.815307\n",
            "[342]\tvalidation_0-auc:0.815085\n",
            "[343]\tvalidation_0-auc:0.815005\n",
            "[344]\tvalidation_0-auc:0.814914\n",
            "[345]\tvalidation_0-auc:0.814861\n",
            "[346]\tvalidation_0-auc:0.814853\n",
            "[347]\tvalidation_0-auc:0.815017\n",
            "[348]\tvalidation_0-auc:0.815058\n",
            "[349]\tvalidation_0-auc:0.815252\n",
            "[350]\tvalidation_0-auc:0.815304\n",
            "[351]\tvalidation_0-auc:0.815264\n",
            "[352]\tvalidation_0-auc:0.815269\n",
            "[353]\tvalidation_0-auc:0.815093\n",
            "[354]\tvalidation_0-auc:0.815161\n",
            "[355]\tvalidation_0-auc:0.814977\n",
            "[356]\tvalidation_0-auc:0.815137\n",
            "[357]\tvalidation_0-auc:0.815198\n",
            "[358]\tvalidation_0-auc:0.815271\n",
            "[359]\tvalidation_0-auc:0.815299\n",
            "[360]\tvalidation_0-auc:0.815364\n",
            "[361]\tvalidation_0-auc:0.815444\n",
            "[362]\tvalidation_0-auc:0.815638\n",
            "[363]\tvalidation_0-auc:0.815596\n",
            "[364]\tvalidation_0-auc:0.815582\n",
            "[365]\tvalidation_0-auc:0.815625\n",
            "[366]\tvalidation_0-auc:0.815604\n",
            "[367]\tvalidation_0-auc:0.815577\n",
            "[368]\tvalidation_0-auc:0.815586\n",
            "[369]\tvalidation_0-auc:0.815771\n",
            "[370]\tvalidation_0-auc:0.815879\n",
            "[371]\tvalidation_0-auc:0.815971\n",
            "[372]\tvalidation_0-auc:0.816138\n",
            "[373]\tvalidation_0-auc:0.816343\n",
            "[374]\tvalidation_0-auc:0.816206\n",
            "[375]\tvalidation_0-auc:0.816218\n",
            "[376]\tvalidation_0-auc:0.816277\n",
            "[377]\tvalidation_0-auc:0.816418\n",
            "[378]\tvalidation_0-auc:0.816345\n",
            "[379]\tvalidation_0-auc:0.816409\n",
            "[380]\tvalidation_0-auc:0.816359\n",
            "[381]\tvalidation_0-auc:0.815928\n",
            "[382]\tvalidation_0-auc:0.815987\n",
            "[383]\tvalidation_0-auc:0.815974\n",
            "[384]\tvalidation_0-auc:0.816011\n",
            "[385]\tvalidation_0-auc:0.81568\n",
            "[386]\tvalidation_0-auc:0.815825\n",
            "[387]\tvalidation_0-auc:0.815897\n",
            "[388]\tvalidation_0-auc:0.815948\n",
            "[389]\tvalidation_0-auc:0.816101\n",
            "[390]\tvalidation_0-auc:0.816342\n",
            "[391]\tvalidation_0-auc:0.816558\n",
            "[392]\tvalidation_0-auc:0.81659\n",
            "[393]\tvalidation_0-auc:0.816457\n",
            "[394]\tvalidation_0-auc:0.816455\n",
            "[395]\tvalidation_0-auc:0.81644\n",
            "[396]\tvalidation_0-auc:0.816577\n",
            "[397]\tvalidation_0-auc:0.816762\n",
            "[398]\tvalidation_0-auc:0.816885\n",
            "[399]\tvalidation_0-auc:0.817009\n",
            "[400]\tvalidation_0-auc:0.817003\n",
            "[401]\tvalidation_0-auc:0.817278\n",
            "[402]\tvalidation_0-auc:0.817108\n",
            "[403]\tvalidation_0-auc:0.817221\n",
            "[404]\tvalidation_0-auc:0.817444\n",
            "[405]\tvalidation_0-auc:0.817534\n",
            "[406]\tvalidation_0-auc:0.817603\n",
            "[407]\tvalidation_0-auc:0.817542\n",
            "[408]\tvalidation_0-auc:0.817557\n",
            "[409]\tvalidation_0-auc:0.81758\n",
            "[410]\tvalidation_0-auc:0.817703\n",
            "[411]\tvalidation_0-auc:0.817655\n",
            "[412]\tvalidation_0-auc:0.817766\n",
            "[413]\tvalidation_0-auc:0.817846\n",
            "[414]\tvalidation_0-auc:0.817804\n",
            "[415]\tvalidation_0-auc:0.817695\n",
            "[416]\tvalidation_0-auc:0.817925\n",
            "[417]\tvalidation_0-auc:0.817905\n",
            "[418]\tvalidation_0-auc:0.818027\n",
            "[419]\tvalidation_0-auc:0.818277\n",
            "[420]\tvalidation_0-auc:0.818371\n",
            "[421]\tvalidation_0-auc:0.81818\n",
            "[422]\tvalidation_0-auc:0.818182\n",
            "[423]\tvalidation_0-auc:0.81808\n",
            "[424]\tvalidation_0-auc:0.818009\n",
            "[425]\tvalidation_0-auc:0.817986\n",
            "[426]\tvalidation_0-auc:0.817971\n",
            "[427]\tvalidation_0-auc:0.817892\n",
            "[428]\tvalidation_0-auc:0.817977\n",
            "[429]\tvalidation_0-auc:0.817862\n",
            "[430]\tvalidation_0-auc:0.817855\n",
            "[431]\tvalidation_0-auc:0.817887\n",
            "[432]\tvalidation_0-auc:0.818141\n",
            "[433]\tvalidation_0-auc:0.818134\n",
            "[434]\tvalidation_0-auc:0.818215\n",
            "[435]\tvalidation_0-auc:0.81812\n",
            "[436]\tvalidation_0-auc:0.81817\n",
            "[437]\tvalidation_0-auc:0.818308\n",
            "[438]\tvalidation_0-auc:0.818316\n",
            "[439]\tvalidation_0-auc:0.818432\n",
            "[440]\tvalidation_0-auc:0.81848\n",
            "[441]\tvalidation_0-auc:0.818529\n",
            "[442]\tvalidation_0-auc:0.818618\n",
            "[443]\tvalidation_0-auc:0.818538\n",
            "[444]\tvalidation_0-auc:0.818522\n",
            "[445]\tvalidation_0-auc:0.818613\n",
            "[446]\tvalidation_0-auc:0.818602\n",
            "[447]\tvalidation_0-auc:0.818732\n",
            "[448]\tvalidation_0-auc:0.818991\n",
            "[449]\tvalidation_0-auc:0.819027\n",
            "[450]\tvalidation_0-auc:0.819102\n",
            "[451]\tvalidation_0-auc:0.819095\n",
            "[452]\tvalidation_0-auc:0.819136\n",
            "[453]\tvalidation_0-auc:0.819236\n",
            "[454]\tvalidation_0-auc:0.819012\n",
            "[455]\tvalidation_0-auc:0.818781\n",
            "[456]\tvalidation_0-auc:0.81878\n",
            "[457]\tvalidation_0-auc:0.818822\n",
            "[458]\tvalidation_0-auc:0.81877\n",
            "[459]\tvalidation_0-auc:0.818712\n",
            "[460]\tvalidation_0-auc:0.818758\n",
            "[461]\tvalidation_0-auc:0.818758\n",
            "[462]\tvalidation_0-auc:0.818831\n",
            "[463]\tvalidation_0-auc:0.818873\n",
            "[464]\tvalidation_0-auc:0.818829\n",
            "[465]\tvalidation_0-auc:0.818856\n",
            "[466]\tvalidation_0-auc:0.818834\n",
            "[467]\tvalidation_0-auc:0.818639\n",
            "[468]\tvalidation_0-auc:0.818722\n",
            "[469]\tvalidation_0-auc:0.818844\n",
            "[470]\tvalidation_0-auc:0.818794\n",
            "[471]\tvalidation_0-auc:0.819085\n",
            "[472]\tvalidation_0-auc:0.819483\n",
            "[473]\tvalidation_0-auc:0.819409\n",
            "[474]\tvalidation_0-auc:0.819455\n",
            "[475]\tvalidation_0-auc:0.819551\n",
            "[476]\tvalidation_0-auc:0.819606\n",
            "[477]\tvalidation_0-auc:0.819595\n",
            "[478]\tvalidation_0-auc:0.819597\n",
            "[479]\tvalidation_0-auc:0.819616\n",
            "[480]\tvalidation_0-auc:0.819442\n",
            "[481]\tvalidation_0-auc:0.819486\n",
            "[482]\tvalidation_0-auc:0.819465\n",
            "[483]\tvalidation_0-auc:0.819264\n",
            "[484]\tvalidation_0-auc:0.819338\n",
            "[485]\tvalidation_0-auc:0.819299\n",
            "[486]\tvalidation_0-auc:0.819338\n",
            "[487]\tvalidation_0-auc:0.819352\n",
            "[488]\tvalidation_0-auc:0.819492\n",
            "[489]\tvalidation_0-auc:0.819547\n",
            "[490]\tvalidation_0-auc:0.81965\n",
            "[491]\tvalidation_0-auc:0.819423\n",
            "[492]\tvalidation_0-auc:0.819278\n",
            "[493]\tvalidation_0-auc:0.819424\n",
            "[494]\tvalidation_0-auc:0.819727\n",
            "[495]\tvalidation_0-auc:0.819897\n",
            "[496]\tvalidation_0-auc:0.819946\n",
            "[497]\tvalidation_0-auc:0.819986\n",
            "[498]\tvalidation_0-auc:0.819986\n",
            "[499]\tvalidation_0-auc:0.820006\n",
            "[500]\tvalidation_0-auc:0.820114\n",
            "[501]\tvalidation_0-auc:0.820249\n",
            "[502]\tvalidation_0-auc:0.820231\n",
            "[503]\tvalidation_0-auc:0.820252\n",
            "[504]\tvalidation_0-auc:0.820072\n",
            "[505]\tvalidation_0-auc:0.820127\n",
            "[506]\tvalidation_0-auc:0.820156\n",
            "[507]\tvalidation_0-auc:0.820177\n",
            "[508]\tvalidation_0-auc:0.820243\n",
            "[509]\tvalidation_0-auc:0.820338\n",
            "[510]\tvalidation_0-auc:0.820461\n",
            "[511]\tvalidation_0-auc:0.820419\n",
            "[512]\tvalidation_0-auc:0.820637\n",
            "[513]\tvalidation_0-auc:0.820726\n",
            "[514]\tvalidation_0-auc:0.820549\n",
            "[515]\tvalidation_0-auc:0.820485\n",
            "[516]\tvalidation_0-auc:0.820674\n",
            "[517]\tvalidation_0-auc:0.820621\n",
            "[518]\tvalidation_0-auc:0.820649\n",
            "[519]\tvalidation_0-auc:0.820662\n",
            "[520]\tvalidation_0-auc:0.820746\n",
            "[521]\tvalidation_0-auc:0.820706\n",
            "[522]\tvalidation_0-auc:0.820572\n",
            "[523]\tvalidation_0-auc:0.820478\n",
            "[524]\tvalidation_0-auc:0.820429\n",
            "[525]\tvalidation_0-auc:0.820604\n",
            "[526]\tvalidation_0-auc:0.820608\n",
            "[527]\tvalidation_0-auc:0.820623\n",
            "[528]\tvalidation_0-auc:0.820843\n",
            "[529]\tvalidation_0-auc:0.821101\n",
            "[530]\tvalidation_0-auc:0.821142\n",
            "[531]\tvalidation_0-auc:0.821388\n",
            "[532]\tvalidation_0-auc:0.821463\n",
            "[533]\tvalidation_0-auc:0.821525\n",
            "[534]\tvalidation_0-auc:0.821449\n",
            "[535]\tvalidation_0-auc:0.821465\n",
            "[536]\tvalidation_0-auc:0.82134\n",
            "[537]\tvalidation_0-auc:0.82143\n",
            "[538]\tvalidation_0-auc:0.821396\n",
            "[539]\tvalidation_0-auc:0.82158\n",
            "[540]\tvalidation_0-auc:0.821659\n",
            "[541]\tvalidation_0-auc:0.821795\n",
            "[542]\tvalidation_0-auc:0.821736\n",
            "[543]\tvalidation_0-auc:0.821716\n",
            "[544]\tvalidation_0-auc:0.821782\n",
            "[545]\tvalidation_0-auc:0.82154\n",
            "[546]\tvalidation_0-auc:0.821405\n",
            "[547]\tvalidation_0-auc:0.821356\n",
            "[548]\tvalidation_0-auc:0.821353\n",
            "[549]\tvalidation_0-auc:0.821463\n",
            "[550]\tvalidation_0-auc:0.821472\n",
            "[551]\tvalidation_0-auc:0.821698\n",
            "[552]\tvalidation_0-auc:0.821576\n",
            "[553]\tvalidation_0-auc:0.82159\n",
            "[554]\tvalidation_0-auc:0.821658\n",
            "[555]\tvalidation_0-auc:0.821781\n",
            "[556]\tvalidation_0-auc:0.821555\n",
            "[557]\tvalidation_0-auc:0.821395\n",
            "[558]\tvalidation_0-auc:0.821514\n",
            "[559]\tvalidation_0-auc:0.821422\n",
            "[560]\tvalidation_0-auc:0.821307\n",
            "[561]\tvalidation_0-auc:0.821409\n",
            "[562]\tvalidation_0-auc:0.821493\n",
            "[563]\tvalidation_0-auc:0.821493\n",
            "[564]\tvalidation_0-auc:0.821548\n",
            "[565]\tvalidation_0-auc:0.821695\n",
            "[566]\tvalidation_0-auc:0.821825\n",
            "[567]\tvalidation_0-auc:0.82167\n",
            "[568]\tvalidation_0-auc:0.821713\n",
            "[569]\tvalidation_0-auc:0.821873\n",
            "[570]\tvalidation_0-auc:0.821975\n",
            "[571]\tvalidation_0-auc:0.821951\n",
            "[572]\tvalidation_0-auc:0.821808\n",
            "[573]\tvalidation_0-auc:0.821799\n",
            "[574]\tvalidation_0-auc:0.821679\n",
            "[575]\tvalidation_0-auc:0.821537\n",
            "[576]\tvalidation_0-auc:0.821572\n",
            "[577]\tvalidation_0-auc:0.821521\n",
            "[578]\tvalidation_0-auc:0.821583\n",
            "[579]\tvalidation_0-auc:0.821625\n",
            "[580]\tvalidation_0-auc:0.821651\n",
            "[581]\tvalidation_0-auc:0.821471\n",
            "[582]\tvalidation_0-auc:0.821454\n",
            "[583]\tvalidation_0-auc:0.821475\n",
            "[584]\tvalidation_0-auc:0.8214\n",
            "[585]\tvalidation_0-auc:0.821443\n",
            "[586]\tvalidation_0-auc:0.821504\n",
            "[587]\tvalidation_0-auc:0.821667\n",
            "[588]\tvalidation_0-auc:0.821582\n",
            "[589]\tvalidation_0-auc:0.821522\n",
            "[590]\tvalidation_0-auc:0.821501\n",
            "[591]\tvalidation_0-auc:0.8214\n",
            "[592]\tvalidation_0-auc:0.821382\n",
            "[593]\tvalidation_0-auc:0.821465\n",
            "[594]\tvalidation_0-auc:0.821361\n",
            "[595]\tvalidation_0-auc:0.821455\n",
            "[596]\tvalidation_0-auc:0.821367\n",
            "[597]\tvalidation_0-auc:0.821243\n",
            "[598]\tvalidation_0-auc:0.821289\n",
            "[599]\tvalidation_0-auc:0.821171\n",
            "[600]\tvalidation_0-auc:0.82115\n",
            "[601]\tvalidation_0-auc:0.821222\n",
            "[602]\tvalidation_0-auc:0.82131\n",
            "[603]\tvalidation_0-auc:0.821471\n",
            "[604]\tvalidation_0-auc:0.821531\n",
            "[605]\tvalidation_0-auc:0.821665\n",
            "[606]\tvalidation_0-auc:0.8216\n",
            "[607]\tvalidation_0-auc:0.821716\n",
            "[608]\tvalidation_0-auc:0.821726\n",
            "[609]\tvalidation_0-auc:0.821785\n",
            "[610]\tvalidation_0-auc:0.821802\n",
            "[611]\tvalidation_0-auc:0.821721\n",
            "[612]\tvalidation_0-auc:0.82175\n",
            "[613]\tvalidation_0-auc:0.821776\n",
            "[614]\tvalidation_0-auc:0.821713\n",
            "[615]\tvalidation_0-auc:0.821693\n",
            "[616]\tvalidation_0-auc:0.82168\n",
            "[617]\tvalidation_0-auc:0.821686\n",
            "[618]\tvalidation_0-auc:0.821737\n",
            "[619]\tvalidation_0-auc:0.821781\n",
            "[620]\tvalidation_0-auc:0.821752\n",
            "[621]\tvalidation_0-auc:0.821935\n",
            "[622]\tvalidation_0-auc:0.822012\n",
            "[623]\tvalidation_0-auc:0.822171\n",
            "[624]\tvalidation_0-auc:0.822304\n",
            "[625]\tvalidation_0-auc:0.822359\n",
            "[626]\tvalidation_0-auc:0.822332\n",
            "[627]\tvalidation_0-auc:0.822187\n",
            "[628]\tvalidation_0-auc:0.822369\n",
            "[629]\tvalidation_0-auc:0.822468\n",
            "[630]\tvalidation_0-auc:0.822336\n",
            "[631]\tvalidation_0-auc:0.822457\n",
            "[632]\tvalidation_0-auc:0.822537\n",
            "[633]\tvalidation_0-auc:0.822631\n",
            "[634]\tvalidation_0-auc:0.822472\n",
            "[635]\tvalidation_0-auc:0.822483\n",
            "[636]\tvalidation_0-auc:0.822438\n",
            "[637]\tvalidation_0-auc:0.822466\n",
            "[638]\tvalidation_0-auc:0.822516\n",
            "[639]\tvalidation_0-auc:0.822666\n",
            "[640]\tvalidation_0-auc:0.822692\n",
            "[641]\tvalidation_0-auc:0.822787\n",
            "[642]\tvalidation_0-auc:0.822755\n",
            "[643]\tvalidation_0-auc:0.822736\n",
            "[644]\tvalidation_0-auc:0.822557\n",
            "[645]\tvalidation_0-auc:0.822533\n",
            "[646]\tvalidation_0-auc:0.822394\n",
            "[647]\tvalidation_0-auc:0.822355\n",
            "[648]\tvalidation_0-auc:0.822383\n",
            "[649]\tvalidation_0-auc:0.822476\n",
            "[650]\tvalidation_0-auc:0.822397\n",
            "[651]\tvalidation_0-auc:0.822343\n",
            "[652]\tvalidation_0-auc:0.822336\n",
            "[653]\tvalidation_0-auc:0.822323\n",
            "[654]\tvalidation_0-auc:0.822547\n",
            "[655]\tvalidation_0-auc:0.822585\n",
            "[656]\tvalidation_0-auc:0.82255\n",
            "[657]\tvalidation_0-auc:0.822544\n",
            "[658]\tvalidation_0-auc:0.822627\n",
            "[659]\tvalidation_0-auc:0.822574\n",
            "[660]\tvalidation_0-auc:0.822565\n",
            "[661]\tvalidation_0-auc:0.822603\n",
            "[662]\tvalidation_0-auc:0.822614\n",
            "[663]\tvalidation_0-auc:0.822647\n",
            "[664]\tvalidation_0-auc:0.82279\n",
            "[665]\tvalidation_0-auc:0.822726\n",
            "[666]\tvalidation_0-auc:0.822783\n",
            "[667]\tvalidation_0-auc:0.822747\n",
            "[668]\tvalidation_0-auc:0.822848\n",
            "[669]\tvalidation_0-auc:0.82281\n",
            "[670]\tvalidation_0-auc:0.822826\n",
            "[671]\tvalidation_0-auc:0.822637\n",
            "[672]\tvalidation_0-auc:0.822653\n",
            "[673]\tvalidation_0-auc:0.822625\n",
            "[674]\tvalidation_0-auc:0.822547\n",
            "[675]\tvalidation_0-auc:0.82251\n",
            "[676]\tvalidation_0-auc:0.822443\n",
            "[677]\tvalidation_0-auc:0.822366\n",
            "[678]\tvalidation_0-auc:0.822372\n",
            "[679]\tvalidation_0-auc:0.82259\n",
            "[680]\tvalidation_0-auc:0.822624\n",
            "[681]\tvalidation_0-auc:0.822603\n",
            "[682]\tvalidation_0-auc:0.822689\n",
            "[683]\tvalidation_0-auc:0.822772\n",
            "[684]\tvalidation_0-auc:0.822778\n",
            "[685]\tvalidation_0-auc:0.822893\n",
            "[686]\tvalidation_0-auc:0.823027\n",
            "[687]\tvalidation_0-auc:0.823013\n",
            "[688]\tvalidation_0-auc:0.823037\n",
            "[689]\tvalidation_0-auc:0.823028\n",
            "[690]\tvalidation_0-auc:0.822991\n",
            "[691]\tvalidation_0-auc:0.823031\n",
            "[692]\tvalidation_0-auc:0.822859\n",
            "[693]\tvalidation_0-auc:0.822951\n",
            "[694]\tvalidation_0-auc:0.82306\n",
            "[695]\tvalidation_0-auc:0.822781\n",
            "[696]\tvalidation_0-auc:0.823017\n",
            "[697]\tvalidation_0-auc:0.822993\n",
            "[698]\tvalidation_0-auc:0.822968\n",
            "[699]\tvalidation_0-auc:0.82284\n",
            "[700]\tvalidation_0-auc:0.822872\n",
            "[701]\tvalidation_0-auc:0.822933\n",
            "[702]\tvalidation_0-auc:0.822803\n",
            "[703]\tvalidation_0-auc:0.822796\n",
            "[704]\tvalidation_0-auc:0.822727\n",
            "[705]\tvalidation_0-auc:0.822756\n",
            "[706]\tvalidation_0-auc:0.822843\n",
            "[707]\tvalidation_0-auc:0.822934\n",
            "[708]\tvalidation_0-auc:0.82287\n",
            "[709]\tvalidation_0-auc:0.822896\n",
            "[710]\tvalidation_0-auc:0.822878\n",
            "[711]\tvalidation_0-auc:0.822795\n",
            "[712]\tvalidation_0-auc:0.822687\n",
            "[713]\tvalidation_0-auc:0.822542\n",
            "[714]\tvalidation_0-auc:0.822535\n",
            "[715]\tvalidation_0-auc:0.822447\n",
            "[716]\tvalidation_0-auc:0.822572\n",
            "[717]\tvalidation_0-auc:0.822633\n",
            "[718]\tvalidation_0-auc:0.822618\n",
            "[719]\tvalidation_0-auc:0.822678\n",
            "[720]\tvalidation_0-auc:0.822781\n",
            "[721]\tvalidation_0-auc:0.822716\n",
            "[722]\tvalidation_0-auc:0.82271\n",
            "[723]\tvalidation_0-auc:0.822756\n",
            "[724]\tvalidation_0-auc:0.822681\n",
            "[725]\tvalidation_0-auc:0.822807\n",
            "[726]\tvalidation_0-auc:0.822906\n",
            "[727]\tvalidation_0-auc:0.822919\n",
            "[728]\tvalidation_0-auc:0.823007\n",
            "[729]\tvalidation_0-auc:0.823019\n",
            "[730]\tvalidation_0-auc:0.822946\n",
            "[731]\tvalidation_0-auc:0.822918\n",
            "[732]\tvalidation_0-auc:0.822934\n",
            "[733]\tvalidation_0-auc:0.822937\n",
            "[734]\tvalidation_0-auc:0.822875\n",
            "[735]\tvalidation_0-auc:0.822977\n",
            "[736]\tvalidation_0-auc:0.82294\n",
            "[737]\tvalidation_0-auc:0.822774\n",
            "[738]\tvalidation_0-auc:0.822763\n",
            "[739]\tvalidation_0-auc:0.822812\n",
            "[740]\tvalidation_0-auc:0.8228\n",
            "[741]\tvalidation_0-auc:0.822807\n",
            "[742]\tvalidation_0-auc:0.822723\n",
            "[743]\tvalidation_0-auc:0.822713\n",
            "[744]\tvalidation_0-auc:0.822814\n",
            "[745]\tvalidation_0-auc:0.822713\n",
            "[746]\tvalidation_0-auc:0.822706\n",
            "[747]\tvalidation_0-auc:0.822708\n",
            "[748]\tvalidation_0-auc:0.822754\n",
            "[749]\tvalidation_0-auc:0.822692\n",
            "[750]\tvalidation_0-auc:0.822662\n",
            "[751]\tvalidation_0-auc:0.82276\n",
            "[752]\tvalidation_0-auc:0.822747\n",
            "[753]\tvalidation_0-auc:0.822797\n",
            "[754]\tvalidation_0-auc:0.822632\n",
            "[755]\tvalidation_0-auc:0.822453\n",
            "[756]\tvalidation_0-auc:0.822609\n",
            "[757]\tvalidation_0-auc:0.822569\n",
            "[758]\tvalidation_0-auc:0.822438\n",
            "[759]\tvalidation_0-auc:0.822489\n",
            "[760]\tvalidation_0-auc:0.822594\n",
            "[761]\tvalidation_0-auc:0.822666\n",
            "[762]\tvalidation_0-auc:0.822689\n",
            "[763]\tvalidation_0-auc:0.822795\n",
            "[764]\tvalidation_0-auc:0.82271\n",
            "[765]\tvalidation_0-auc:0.822792\n",
            "[766]\tvalidation_0-auc:0.822748\n",
            "[767]\tvalidation_0-auc:0.822784\n",
            "[768]\tvalidation_0-auc:0.822778\n",
            "[769]\tvalidation_0-auc:0.822839\n",
            "[770]\tvalidation_0-auc:0.822858\n",
            "[771]\tvalidation_0-auc:0.82282\n",
            "[772]\tvalidation_0-auc:0.822994\n",
            "[773]\tvalidation_0-auc:0.82294\n",
            "[774]\tvalidation_0-auc:0.822738\n",
            "[775]\tvalidation_0-auc:0.822814\n",
            "[776]\tvalidation_0-auc:0.822831\n",
            "[777]\tvalidation_0-auc:0.822649\n",
            "[778]\tvalidation_0-auc:0.822617\n",
            "[779]\tvalidation_0-auc:0.822598\n",
            "[780]\tvalidation_0-auc:0.822634\n",
            "[781]\tvalidation_0-auc:0.822716\n",
            "[782]\tvalidation_0-auc:0.822677\n",
            "[783]\tvalidation_0-auc:0.822504\n",
            "[784]\tvalidation_0-auc:0.822621\n",
            "[785]\tvalidation_0-auc:0.822637\n",
            "[786]\tvalidation_0-auc:0.822598\n",
            "[787]\tvalidation_0-auc:0.822583\n",
            "[788]\tvalidation_0-auc:0.822532\n",
            "[789]\tvalidation_0-auc:0.822703\n",
            "[790]\tvalidation_0-auc:0.822623\n",
            "[791]\tvalidation_0-auc:0.822694\n",
            "[792]\tvalidation_0-auc:0.822631\n",
            "[793]\tvalidation_0-auc:0.822681\n",
            "[794]\tvalidation_0-auc:0.822685\n",
            "Stopping. Best iteration:\n",
            "[694]\tvalidation_0-auc:0.82306\n",
            "\n",
            "train score is 0.811341740424532, test_score is 0.44477390659747956\n",
            "----------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.84      0.89      3666\n",
            "           1       0.33      0.66      0.44       453\n",
            "\n",
            "    accuracy                           0.82      4119\n",
            "   macro avg       0.64      0.75      0.67      4119\n",
            "weighted avg       0.88      0.82      0.84      4119\n",
            "\n",
            "Searching for best hyperparameter... \n",
            "Running Cross Val \n",
            "Returning 5fold CV Scores\n",
            "--------------------------------------\n",
            "stratifiedKFold score 0.805029114927468, Kfold_score 0.8031568708346392, params {'max_depth': 4, 'gamma': '0.175', 'learning_rate': '0.142', 'colsample_bytree': '0.695'}\n",
            "stratifiedKFold score 0.7700439404507256, Kfold_score 0.7706248044814836, params {'max_depth': 4, 'gamma': '0.209', 'learning_rate': '0.074', 'colsample_bytree': '0.589'}\n",
            "stratifiedKFold score 0.7974378001677538, Kfold_score 0.7968160617406324, params {'max_depth': 3, 'gamma': '0.405', 'learning_rate': '0.422', 'colsample_bytree': '0.383'}\n",
            "stratifiedKFold score 0.7405033366921777, Kfold_score 0.7406565729913808, params {'max_depth': 2, 'gamma': '0.345', 'learning_rate': '0.221', 'colsample_bytree': '0.355'}\n",
            "stratifiedKFold score 0.7579093657803149, Kfold_score 0.758202023180468, params {'max_depth': 2, 'gamma': '0.247', 'learning_rate': '0.294', 'colsample_bytree': '0.737'}\n",
            "stratifiedKFold score 0.8644296620429761, Kfold_score 0.8641361715400612, params {'max_depth': 5, 'gamma': '0.368', 'learning_rate': '0.323', 'colsample_bytree': '0.848'}\n",
            "stratifiedKFold score 0.8230875691498609, Kfold_score 0.8208601490551792, params {'max_depth': 4, 'gamma': '0.082', 'learning_rate': '0.386', 'colsample_bytree': '0.366'}\n",
            "stratifiedKFold score 0.8456389324110489, Kfold_score 0.8447909852073808, params {'max_depth': 4, 'gamma': '0.058', 'learning_rate': '0.486', 'colsample_bytree': '0.628'}\n",
            "stratifiedKFold score 0.8109676746007752, Kfold_score 0.8109941646763881, params {'max_depth': 4, 'gamma': '0.158', 'learning_rate': '0.164', 'colsample_bytree': '0.688'}\n",
            "stratifiedKFold score 0.7390347116049558, Kfold_score 0.738761296458121, params {'max_depth': 5, 'gamma': '0.412', 'learning_rate': '0.019', 'colsample_bytree': '0.581'}\n",
            "100%|| 10/10 [21:20<00:00, 128.04s/it, best loss: 0.7390347116049558]\n",
            "--------------------------------------\n",
            "DONE\n",
            "Best Params {'colsample_bytree': 0.5808468132276302, 'gamma': 0.41231111337133525, 'learning_rate': 0.019079043255053066, 'max_depth': 5}\n",
            "--------------------------------------\n",
            "DONE\n",
            "StratifiedKfold Score: 0.71987913488919, KFold Score: 0.720355180213594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nomxNc5wp5OI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d498097-8fcf-490d-870d-aa0cd8da9076"
      },
      "source": [
        "%%writefile main.py\n",
        "from data import preprocess\n",
        "from model import model\n",
        "def main(data):\n",
        "\n",
        "  '''\n",
        "  The Main function to automate the processess\n",
        "\n",
        "  '''\n",
        "\n",
        "  M = model(*preprocess(data))\n",
        "  M.logit()\n",
        "  M.XGB()\n",
        "  M.MLP()\n",
        "\n",
        "  if __name__ == 'main':\n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RSzEqLSfbqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx0q0b3WhGl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}